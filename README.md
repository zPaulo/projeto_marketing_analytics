# ğŸ“Š Marketing Analytics - Fullstack Data Project

<div align="center">

![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)
![Pandas](https://img.shields.io/badge/Pandas-2.3.2+-green.svg)
![Polars](https://img.shields.io/badge/Polars-1.32.3+-orange.svg)
![SQLAlchemy](https://img.shields.io/badge/SQLAlchemy-2.0+-red.svg)
![Status](https://img.shields.io/badge/Status-Em%20Desenvolvimento-yellow.svg)

*Um projeto completo de anÃ¡lise de marketing focado em LTV (Lifetime Value) e Churn Prediction*

</div>

## ğŸ¯ VisÃ£o Geral

Este Ã© um projeto **fullstack de dados** que abrange todo o ciclo de vida de um produto de dados, desde a engenharia de dados atÃ© a ciÃªncia de dados e anÃ¡lise. O objetivo principal Ã© desenvolver modelos preditivos para **Customer Lifetime Value (LTV)** e **Churn Prediction** utilizando dados reais de e-commerce e telecomunicaÃ§Ãµes.

### ğŸš§ Status Atual: Data Engineering
Atualmente, o projeto estÃ¡ na fase de **Data Engineering**, com foco na construÃ§Ã£o de pipelines de dados robustos e escalÃ¡veis.

## ğŸ—ï¸ Arquitetura do Projeto

```mermaid
graph TD
    A[Data Sources] --> B[Data Engineering]
    B --> C[Data Analytics]
    C --> D[Data Science]
    D --> E[ML Models]
    E --> F[Production API]
    
    B1[ETL Pipelines] --> B
    B2[Data Quality] --> B
    B3[Data Warehouse] --> B
    
    C1[Exploratory Analysis] --> C
    C2[Business Metrics] --> C
    C3[Dashboards] --> C
    
    D1[Feature Engineering] --> D
    D2[Model Training] --> D
    D3[Model Validation] --> D
```

## ğŸ“ Estrutura do Projeto

```
projeto_marketing_analytics/
â”œâ”€â”€ ğŸ—ƒï¸ src/
â”‚   â”œâ”€â”€ ğŸ”§ core/               # ConfiguraÃ§Ãµes e infraestrutura
â”‚   â”‚   â”œâ”€â”€ database.py        # ConexÃµes com banco de dados
â”‚   â”‚   â””â”€â”€ settings.py        # ConfiguraÃ§Ãµes do projeto
â”‚   â”œâ”€â”€ ğŸ“Š data/               # Datasets
â”‚   â”‚   â”œâ”€â”€ Olist_customers/   # Dados de e-commerce brasileiro
â”‚   â”‚   â””â”€â”€ Telco_customer_churn/ # Dados de churn de telecom
â”‚   â”œâ”€â”€ ğŸ—ï¸ models/             # Modelos de dados
â”‚   â”‚   â”œâ”€â”€ base.py           # Modelos base SQLAlchemy
â”‚   â”‚   â””â”€â”€ logger.py         # Sistema de logs
â”‚   â””â”€â”€ ğŸ”„ pipelines/          # Pipelines ETL/ELT
â”‚       â”œâ”€â”€ olist/            # Pipeline Olist (Em desenvolvimento)
â”‚       â””â”€â”€ telco/            # Pipeline Telco (Ativo)
â”œâ”€â”€ ğŸ§ª tests/                  # Testes automatizados
â”œâ”€â”€ ğŸ”„ migrations/             # MigraÃ§Ãµes de banco de dados
â”œâ”€â”€ ğŸ“‹ scripts/                # Scripts de automaÃ§Ã£o
â”œâ”€â”€ ğŸ³ Docker-compose.yml      # OrquestraÃ§Ã£o de containers
â”œâ”€â”€ ğŸ“¦ pyproject.toml          # ConfiguraÃ§Ãµes e dependÃªncias
â””â”€â”€ ğŸ“š README.md               # DocumentaÃ§Ã£o
```

## ğŸ² Datasets

### 1. ğŸ‡§ğŸ‡· Olist E-commerce Dataset
- **Fonte**: Olist (E-commerce brasileiro)
- **PerÃ­odo**: 2016-2018
- **Registros**: ~100k pedidos
- **Objetivo**: AnÃ¡lise de LTV e comportamento de compra

**Tabelas disponÃ­veis:**
- `olist_customers_dataset.csv` - Dados dos clientes
- `olist_orders_dataset.csv` - InformaÃ§Ãµes dos pedidos
- `olist_order_items_dataset.csv` - Itens dos pedidos
- `olist_order_payments_dataset.csv` - Pagamentos
- `olist_order_reviews_dataset.csv` - AvaliaÃ§Ãµes
- `olist_products_dataset.csv` - Produtos
- `olist_sellers_dataset.csv` - Vendedores
- `olist_geolocation_dataset.csv` - Dados geogrÃ¡ficos

### 2. ğŸ“ Telco Customer Churn Dataset
- **Fonte**: Telco (Empresa de telecomunicaÃ§Ãµes)
- **Registros**: ~7k clientes
- **Objetivo**: PrediÃ§Ã£o de churn

**Principais features:**
- InformaÃ§Ãµes demogrÃ¡ficas
- ServiÃ§os contratados
- InformaÃ§Ãµes de conta
- HistÃ³rico de churn

## ğŸ› ï¸ Tecnologias Utilizadas

### Data Engineering
- **Python 3.12+** - Linguagem principal
- **Pandas & Polars** - ManipulaÃ§Ã£o de dados
- **SQLAlchemy** - ORM e database toolkit
- **Alembic** - MigraÃ§Ãµes de banco de dados
- **SQLite** - Banco de dados (desenvolvimento)
- **PyArrow** - Processamento columnar

### DevOps & Tools
- **Docker** - ContainerizaÃ§Ã£o
- **Poetry/UV** - Gerenciamento de dependÃªncias
- **Ruff** - Linting e formataÃ§Ã£o
- **Pytest** - Testes automatizados
- **Taskipy** - AutomaÃ§Ã£o de tarefas

### Futuras ImplementaÃ§Ãµes
- **FastAPI** - API REST (Data Science/Analytics)
- **Streamlit/Plotly** - Dashboards interativos
- **Scikit-learn/XGBoost** - Machine Learning
- **MLflow** - MLOps
- **PostgreSQL** - Banco de dados (produÃ§Ã£o)

## ğŸš€ Quick Start

### PrÃ©-requisitos
- Python 3.12+
- UV (recomendado) ou Poetry

### 1. Clone o repositÃ³rio
```bash
git clone https://github.com/zPaulo/projeto_marketing_analytics.git
cd projeto_marketing_analytics
```

### 2. Instale as dependÃªncias
```bash
# Com UV (recomendado)
uv sync

# Ou com Poetry
poetry install
```

### 3. Configure o banco de dados
```bash
# Execute as migraÃ§Ãµes
uv run alembic upgrade head
```

### 4. Execute o pipeline
```bash
# Execute o pipeline principal
uv run python src/main.py
```

## ğŸ”„ Pipelines Implementados

### Pipeline Telco (âœ… Ativo)
**Arquitetura ELT:**
1. **Extract** - Carrega dados do CSV
2. **Load** - Insere dados brutos no banco
3. **Transform** - Aplica limpeza e transformaÃ§Ãµes

**ExecuÃ§Ã£o:**
```python
from src.pipelines.telco.pipeline import TelcoPipeline

pipeline = TelcoPipeline()
await pipeline.run_elt()
```

### Pipeline Olist (ğŸš§ Em desenvolvimento)
- ExtraÃ§Ã£o de mÃºltiplas tabelas
- Joins complexos entre entidades
- CÃ¡lculo de mÃ©tricas de negÃ³cio

## ğŸ“Š Roadmap do Projeto

### ğŸ¯ Fase 1: Data Engineering (Atual)
- [x] Estrutura base do projeto
- [x] Pipeline Telco implementado
- [x] Sistema de logs e monitoramento
- [x] Testes automatizados
- [ ] Pipeline Olist
- [ ] Data Quality checks
- [ ] DocumentaÃ§Ã£o completa das pipelines

### ğŸ¯ Fase 2: Data Analytics
- [ ] AnÃ¡lise exploratÃ³ria dos dados
- [ ] MÃ©tricas de negÃ³cio (LTV, Churn Rate, etc.)
- [ ] Dashboards interativos
- [ ] Reports automatizados

### ğŸ¯ Fase 3: Data Science
- [ ] Feature Engineering avanÃ§ado
- [ ] Modelos de Churn Prediction
- [ ] Modelos de LTV
- [ ] A/B Testing framework
- [ ] MLOps pipeline

### ğŸ¯ Fase 4: Production
- [ ] API REST para modelos
- [ ] Interface web
- [ ] Monitoramento de modelos
- [ ] CI/CD completo

## ğŸ§ª Testes

Execute os testes com:
```bash
# Todos os testes
uv run pytest

# Com coverage
uv run pytest --cov=src

# EspecÃ­ficos
uv run pytest tests/test_pipelines/
```

## ğŸ“ Comandos Ãšteis

```bash
# Linting e formataÃ§Ã£o
uv run task lint
uv run task format

# Testes
uv run task test

# MigraÃ§Ãµes
uv run alembic revision --autogenerate -m "descriÃ§Ã£o"
uv run alembic upgrade head
```

## ğŸ¤ Contribuindo

1. FaÃ§a um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

## ğŸ“ Contato

**Paulo** - [@zPaulo](https://github.com/zPaulo)

Link do Projeto: [https://github.com/zPaulo/projeto_marketing_analytics](https://github.com/zPaulo/projeto_marketing_analytics)

---

<div align="center">

**â­ Se este projeto te ajudou, considere dar uma estrela!**

*Desenvolvido com â¤ï¸ para a comunidade de dados*

</div>
